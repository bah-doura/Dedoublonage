{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\BAH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "import re\n",
    "import docx\n",
    "import nltk\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path = 'C:\\\\Users\\\\BAH\\Work Space\\\\M2_MIAGE\\\\PRM2\\\\TP2\\\\test_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Lecture et conversion d'un fichier PDF en .txt\n",
    "def convertPdfFile(fname, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "\n",
    "    infile = open(fname, 'rb')\n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        interpreter.process_page(page)\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close\n",
    "    str = re.sub(r'[^a-zA-Z0-9èéêîï ]',r' ', text)\n",
    "    return str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabulaires_pdf = convert_pdf(\"test_pdf.pdf\")\n",
    "#print(vocabulaires_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture et conversion d'un fichier .docx en .txt\n",
    "    \n",
    "def convertDocxFile(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        txt = para.text.encode('ascii', 'ignore')\n",
    "        fullText.append(txt)\n",
    "    text =  b''.join(fullText) \n",
    "    str = re.sub(r'[^a-zA-Z0-9èéêîï ]',r' ', text.decode(\"utf-8\"))\n",
    "    return str.lower() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_docx = convert_docx(\"test_docx.docx\")\n",
    "#print(vocabulaires_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture du et conversion en tableau du fichier des vocabulaires\n",
    "def  readVocabulary(path):\n",
    "    f = open(path)\n",
    "    li = []\n",
    "    for ln in f:\n",
    "        li.append(ln.split())\n",
    "    #return re.sub(r'[^a-zA-Z0-9èéêîï ]',r' ', text)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = readVocabulary(\"vocabulaire.txt\")\n",
    "#print(vocabularies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour compter le nombre d'occurance\n",
    "def countOccurences(str, word):\n",
    "    count = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), str))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "str = convert_pdf(\"test_pdf.pdf\")\n",
    "word =\"stage\"\n",
    "print(countOccurences(str.lower(), word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression de stop word dans les fichiers\n",
    "def stopWordFilter(str):\n",
    "    stop_words = set(stopwords.words('french')) \n",
    "    word_tokens = word_tokenize(str) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    text =  ' '.join(filtered_sentence)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#example_sent = \"je suis a la maison et toi tu es chez toi avec java\"\n",
    "#print(stopWordFilter(str))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = createVector(vocabulaires, str)\n",
    "vector2 = createVector(vocabulaires, doc_docx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "dist = np.linalg.norm(vector1-vector1)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lecture des noms de fichier\n",
    "def radFilesNames(path):\n",
    "    i=0\n",
    "    listFilesNames =dict()\n",
    "    for filename in os.listdir(path):\n",
    "        listFilesNames[filename] =\"{}_{}\".format(\"file\",i)\n",
    "        i = i+1\n",
    "    return listFilesNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet de créer un vecteur\n",
    "def createVector(vocabulary, str):\n",
    "    #Suppression de mots inutiles\n",
    "    text = stopWordFilter(str)\n",
    "    #initialisation du vecteur\n",
    "    a = range(len(vocabulary[0]))\n",
    "    a = [i*0 for i in a]\n",
    "    vector = np.array(a)\n",
    "    i=0;\n",
    "    for item in vocabulary[0]:\n",
    "        word = vocabulary[0][i]\n",
    "        #print(word)\n",
    "        vector[i] = countOccurences(text.lower(), word)\n",
    "        i=i+1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 3 0 0 0 0 0 2 0 0 1 0 0 0 0 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "vector1 = createVector(vocabulary, str)\n",
    "print(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet de lire tous les fichiers PDF d'un dans un dossier\n",
    "def createMapOccurence(path, vocabulary):\n",
    "    filesVectors = dict()\n",
    "    duplicateFilesMap = dict()\n",
    "    filesName = radFilesNames(path)\n",
    "    for filename in filesName.keys():\n",
    "        extension =  os.path.splitext(filename)[1]\n",
    "        if extension == '.pdf':\n",
    "            #print(filesVectors+\"\\n\")\n",
    "            text = convertPdfFile(path+'\\\\'+filename)\n",
    "            vector = createVector(vocabulary, text)\n",
    "            #print(vector)\n",
    "            filesVectors[filename]=vector\n",
    "        elif extension == '.docx':\n",
    "           # print(filename+\"\\n\")\n",
    "            text = convertDocxFile((path+'\\\\'+filename))\n",
    "            vector = createVector(vocabulary, text)\n",
    "            #print(vector)\n",
    "            filesVectors[filename]=vector\n",
    "    for file in filesVectors.keys():\n",
    "        currentVecotr = filesVectors.get(file)\n",
    "        i = 1\n",
    "        for key in filesVectors.keys():\n",
    "            vector = filesVectors.get(key)\n",
    "            distance =np.linalg.norm(vector-currentVecotr)\n",
    "            if (distance == 0.0):\n",
    "                index =\"\"\n",
    "                if duplicateFilesMap.get(file) !=\"None\":\n",
    "                    index = duplicateFilesMap.get(file)\n",
    "                newPair = {file:\"{},{}\".format(duplicateFilesMap.get(file), filesName.get(file))}\n",
    "                duplicateFilesMap.update(newPair)\n",
    "    return duplicateFilesMap\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNomberOccurenceFile(mapData):\n",
    "    for k, v in mapData.items():\n",
    "        print (\"{} : {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001-Stage - Développement d'une solution HomeNetWorking.pdf : None,file_0\n",
      "00002-Stage - Développement d'un moteur de recherche Java.pdf : None,file_1,file_1\n",
      "00003-Stage - Etude et développement Java NOSQL.pdf : None,file_2\n",
      "00004-Stage - Développement d'une solution web d'assitance en ligne _Le Mans_.pdf : None,file_3\n",
      "mydoc.docx : None,file_4,file_4\n",
      "test1.pdf : None,file_5,file_5\n",
      "test_docx.docx : None,file_6,file_6\n"
     ]
    }
   ],
   "source": [
    "mapVecotr = createMapOccurence(path, vocabulary)\n",
    "printNomberOccurenceFile(mapVecotr)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
